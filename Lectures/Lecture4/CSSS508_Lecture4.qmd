---
execute: 
  echo: true
  message: false
  warning: false
  fig-format: "svg"
format: 
  revealjs:
    highlight-style: a11y-dark
    reference-location: margin
    theme: lecture_styles.scss
    slide-number: true
    code-link: true
    chalkboard: true
    incremental: false 
    smaller: true
    preview-links: true
    code-line-numbers: true
    history: false
    progress: true
    link-external-icon: true
    code-annotations: hover
---

```{r}
#| echo: false
#| cache: false
require(downlit)
require(xml2)
require(tidyverse)
```

## {#title-slide data-menu-title="Importing, Exporting, and Cleaning Data" background="#1e4655" background-image="../../images/csss-logo.png" background-position="center top 5%" background-size="50%"}


[Importing, Exporting, and Cleaning Data]{.custom-title}

[CS&SS 508 â€¢ Lecture 4]{.custom-subtitle}

[24 October 2023]{.custom-subtitle2}

[Victoria Sass]{.custom-subtitle3}

# Roadmap{.section-title background-color="#99a486"}

---

<br>

Last time, we learned about,

* Best Prectices
  * Code Style
  * Workflow
* Reproducible Research
* Indexing vectors & dataframes in Base `R`

. . . 

Today, we will cover,

* Importing and exporting data
* Cleaning and reshaping data
* Dealing with dates & times
* Controlling factor variables

# Importing and Exporting Data{.section-title background-color="#99a486"}

## Data Packages

R has a *big* user base.  If you are working with a popular data source, it will often have a devoted R package on *CRAN* or *Github*. 

. . . 

Examples:

* [`WDI`](https://vincentarelbundock.github.io/WDI/): World Development Indicators (World Bank)
* [`tidycensus`](https://walker-data.com/tidycensus/): Census and American Community Survey
* [`quantmod`](https://walker-data.com/tidycensus/): financial data from Yahoo, FRED, Google
* [`gssr`](https://kjhealy.github.io/gssr/): The General Social Survey Cumulative Data (1972-2021)
* [`psidR`](https://github.com/floswald/psidR): Panel Study of Income Dynamics (basic & public datasets)

. . . 

If you have an actual data file, you'll have to import it yourself...

## Delimited Text Files

Besides a package, it's easiest when data is stored in a text file. The most commonly encountered delimitd file is a **.csv**.

. . . 

A comma-separated values (.csv) file looks like the following: 

```
"Subject","Depression","Sex","Week","HamD","Imipramine"
101,"Non-endogenous","Second",0,26,NA
101,"Non-endogenous","Second",1,22,NA
101,"Non-endogenous","Second",2,18,4.04305
101,"Non-endogenous","Second",3,7,3.93183
101,"Non-endogenous","Second",4,4,4.33073
101,"Non-endogenous","Second",5,3,4.36945
103,"Non-endogenous","First",0,33,NA
103,"Non-endogenous","First",1,24,NA
103,"Non-endogenous","First",2,15,2.77259
```

## `readr`

R has some built-in functions for importing data, such as `read.table()` and `read.csv()`. 

. . . 

:::: {.columns}

::: {.column width="60%"}
The `readr` package provides similar functions, like `read_csv()`, that have slightly better features:

::: {.incremental}
* Faster!
* Better defaults (e.g. doesn't automatically convert characters to factors)
* A *bit* smarter about dates and times
* Loading progress bars for large files
:::
:::

::: {.column width="40%"}
![](images/readr.png)
:::

::::
. . . 

`readr` is one of the core `tidyverse` packages so loading `tidyverse` will load it too:

```{r}
library(tidyverse)
```

. . . 

Alternatively, you can just load `readr` like so:

```{r}
#| eval: false
library(readr)
```

## `readr` Importing Example

Let's import some data about song ranks on the Billboard Hot 100 in 2000:

```{r}
billboard_2000_raw <- read_csv(file = "data/billboard.csv")
```

. . . 

How do we know it loaded? 

. . . 

Let's look at it!

```{r}
glimpse(billboard_2000_raw)
```

## Alternate Solution

When you import data from an external file you'll also see it in the Global Environment tab in the upper-right pane of RStudio: 

:::: {.columns}

::: {.column width="50%"}
::: {.fragment}
You can also import the data manually!

In the upper right-hand pane of RStudio (make sure you're in the Environment tab), select:

`Import Dataset > From Text (readr)` and browse to the file on your computer^[Ideally you've saved it in your project folder! ðŸ˜Œ].
:::

::: {.fragment}
**Once you've imported the data, you can `copy/paste` the import code from the console into your file!!**

This makes the process *reproducible!*
:::
:::
::: {.column width="50%"}
![](images/data_global_env.png)

:::

::::

## Manual data import

![](images/data_import_manual.png){fig-align="center"}

## Specifying `NA`s 

`NA`s are technically logical (boolean) variables^[We'll cover these more in depth in a couple of weeks.] that indicate a missing value. 

. . . 

Sometimes a particular dataset or file read from a different software will code `NA`s differently than `R`. If that's the case, you can add additional specifications to `read_csv` for what to read in as `NA`.  


```{r}
#| eval: false
billboard_2000_raw <- read_csv(file = "data/billboard.csv", 
                               na = c("N/A", "999"))
```

## Skipping lines

Depending on how the data were input, there may be several lines that precede the beginning of the data table you're interested in importing. You can skip these lines of metadata with the `skip` argument:

```{r}
#| eval: false
billboard_2000_raw <- read_csv(file = "data/billboard.csv", 
                               skip = 1)
```

## Variable names

`read_csv` will automatically take the first row as column names. If you want to rename them you can save yourself some time recoding later on if you specify your preferred variable names upfront with the `col_names` argument. 

. . . 

It takes a character vector to be used as column names (in their order of appearance). 

```{r}
#| eval: false
billboard_2000_raw <- read_csv(file = "data/billboard.csv", 
                               col_names = c("year", "artist", "track", "time", "date_entered", 
                                             paste("wk", 1:76, sep = "_"))) # <1>

billboard_renamed |>  names() |> head(10) # <2>
```

1. `paste` "pastes" together the first argument to the second argument (separated by whatever is specified in the `sep` argument) as character strings. Since the first argument here is a singular value, it is repeated for the entire length of the vector in the second argument. The first several values of `paste("wk", 1:76, sep = "_")` are: `r head(paste("wk", 1:76, sep = "_"))`
2. Our first official usage of the pipe! `names` here returns the column names of our data frame.
. . . 

If you don't have any variable names you can specify that instead. 

```{r}
#| eval: false
billboard_2000_raw <- read_csv(file = "data/billboard.csv", 
                               col_names = FALSE) 
```

## Snake Case

If you simply want to change your variables to snake case (all lower case; words separated by `_`), you can use the function `clean_names()` from the `janitor` package which replaces other punctuation separators with `_`. 

```{r}

# install.packages("janitor") # <1> 
billboard_renamed <- billboard_2000_raw |> 
  janitor::clean_names(numerals = "right") # <2>

billboard_renamed |>  names() |> head(10)
```

1. Run in the console first. 
2. You can call a function without loading its package by specifying its package name followed by `::` before it; <br> The `numerals` argument specifies if you additionally want to put a separator before a number. 

## Other Data File Types with `readr`

The other functions in `readr` employ as similar approach to `read_csv` so the trick is just knowing which to use for what data type. 

::: {.incremental}
* `read_csv2` is separated by semicolons (instead of commas)
* `read_tsv` is separated by tabs
* `read_delim` guesses the delimiter
* `read_fwf` reads in fixed-width-files
* `read_table` is a variation of `fwf` where columns are separated by white space
* `read_log` reads in Apache-style log files
:::

## Other Packages to Read in Data

There are a range of other ways, besides delimited files, that data are stored. 

The following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.

## Other Packages to Read in Data

There are a range of other ways, besides delimited files, that data are stored. 

The following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.

:::: {.columns}
::: {.column width="50%"}
![](images/readxl.png){.absolute top=185 left=135}
:::
::: {.column width="50%"}
* For Excel files (`.xls` or `.xlsx`), use package [`readxl`](https://readxl.tidyverse.org/)^[Functions have additional arguments to read in specific sheets or a range of cells.]
:::
::::

::: aside
Note: For Excel files and Googlesheets You **won't** keep text formatting, color, comments, or merged cells. See the [`openxlsx`](https://ycphs.github.io/openxlsx/) package for those capabilities. Also, [`tidyxl`](https://github.com/nacnudus/tidyxl) can help import non-tabular data from Excel. 
:::

## Other Packages to Read in Data

There are a range of other ways, besides delimited files, that data are stored. 

The following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.

:::: {.columns}
::: {.column width="50%"}
![](images/googlesheets4.png){.absolute top=185 left=135}
:::
::: {.column width="50%"}
* For Excel files (`.xls` or `.xlsx`), use package [`readxl`](https://readxl.tidyverse.org/)^[Functions have additional arguments to read in specific sheets or a range of cells.]
* For Google Docs Spreadsheets, use package [`googlesheets4`](https://googlesheets4.tidyverse.org/)^[Very similar to `readxl` with some slight variations you can read about [here](https://r4ds.hadley.nz/spreadsheets.html#google-sheets).]
:::
::::

::: aside
Note: For Excel files and Googlesheets You **won't** keep text formatting, color, comments, or merged cells. See the [`openxlsx`](https://ycphs.github.io/openxlsx/) package for those capabilities. Also, [`tidyxl`](https://github.com/nacnudus/tidyxl) can help import non-tabular data from Excel. 
:::

## Other Packages to Read in Data

There are a range of other ways, besides delimited files, that data are stored. 

The following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.

:::: {.columns}
::: {.column width="50%"}
![](images/haven.png){.absolute top=185 left=135}
:::
::: {.column width="50%"}
* For Excel files (`.xls` or `.xlsx`), use package [`readxl`](https://readxl.tidyverse.org/)^[Functions have additional arguments to read in specific sheets or a range of cells.]
* For Google Docs Spreadsheets, use package [`googlesheets4`](https://googlesheets4.tidyverse.org/)^[Very similar to `readxl` with some slight variations you can read about [here](https://r4ds.hadley.nz/spreadsheets.html#google-sheets).]
* For Stata, SPSS, and SAS files, use package [`haven`](https://haven.tidyverse.org/)^[SAS, SPSS, and Stata have so-called "labelled" vectors for which `haven` provides a [class](https://haven.tidyverse.org/reference/index.html#labelled-vectors) to represent in `R`. Alternatively, you can get rid of them with [these functions](https://haven.tidyverse.org/reference/index.html#remove-attributes).]
:::
::::

::: aside
Note: For Excel files and Googlesheets You **won't** keep text formatting, color, comments, or merged cells. See the [`openxlsx`](https://ycphs.github.io/openxlsx/) package for those capabilities. Also, [`tidyxl`](https://github.com/nacnudus/tidyxl) can help import non-tabular data from Excel. 
:::

## How does `readr` parse different data types?

For each column in a data frame, `readr` functions pull the first 1000 rows and checks:

```{mermaid}
%%| echo: false
%%| fig-width: 11
%%| fig-height: 5.5
%%| fig-align: center
flowchart LR
    id1(Variable)==>A["1. Does it contain only F, T, FALSE, TRUE, or NA, (ignoring case)?"]==>id2(Logical)
    id1(Variable)==>B["2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)"]==>id3(Number)
    id1(Variable)==>C["3. Does it match the ISO8601 standard?"]==>id4(Date/Date-time)
    id1(Variable)==>D["4. None of the above"]==>id5(String)
    style id1 fill:#1e4655,color:#c7cdac,stroke:#c7cdac
    style id2 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id3 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id4 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id5 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style A fill:#FFFFFF,color:#000000,stroke:#000000
    style B fill:#FFFFFF,color:#000000,stroke:#000000
    style C fill:#FFFFFF,color:#000000,stroke:#000000
    style D fill:#FFFFFF,color:#000000,stroke:#000000

```

## How does `readr` parse different data types?

For each column in a data frame, `readr` functions pull the first 1000 rows and checks: 

```{mermaid}
%%| echo: false
%%| fig-width: 11
%%| fig-height: 5.5
%%| fig-align: center
flowchart LR
    id1(Variable)==>A["1. Does it contain only F, T, FALSE, TRUE, or NA (ignoring case)?"]==>id2(Logical)
    id1(Variable)==>B["2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)"]==>id3(Number)
    id1(Variable)==>C["3. Does it match the ISO8601 standard?"]==>id4(Date/Date-time)
    id1(Variable)==>D["4. None of the above"]==>id5(String)
    style id1 fill:#1e4655,color:#c7cdac,stroke:#c7cdac
    style id2 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id3 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id4 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id5 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style A fill:#ffa07a,color:#000000,stroke:#000000
    style B fill:#FFFFFF,color:#000000,stroke:#000000
    style C fill:#FFFFFF,color:#000000,stroke:#000000
    style D fill:#FFFFFF,color:#000000,stroke:#000000

```

## How does `readr` parse different data types?

For each column in a data frame, `readr` functions pull the first 1000 rows and checks:

```{mermaid}
%%| echo: false
%%| fig-width: 11
%%| fig-height: 5.5
%%| fig-align: center
flowchart LR
    id1(Variable)==>A["1. Does it contain only F, T, FALSE, TRUE, or NA, (ignoring case)?"]==>id2(Logical)
    id1(Variable)==>B["2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)"]==>id3(Number)
    id1(Variable)==>C["3. Does it match the ISO8601 standard?"]==>id4(Date/Date-time)
    id1(Variable)==>D["4. None of the above"]==>id5(String)
    style id1 fill:#1e4655,color:#c7cdac,stroke:#c7cdac
    style id2 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id3 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id4 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id5 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style A fill:#FFFFFF,color:#000000,stroke:#000000
    style B fill:#ffa07a,color:#000000,stroke:#000000
    style C fill:#FFFFFF,color:#000000,stroke:#000000
    style D fill:#FFFFFF,color:#000000,stroke:#000000

```

## How does `readr` parse different data types?

For each column in a data frame, `readr` functions pull the first 1000 rows and checks:

```{mermaid}
%%| echo: false
%%| fig-width: 11
%%| fig-height: 5.5
%%| fig-align: center
flowchart LR
    id1(Variable)==>A["1. Does it contain only F, T, FALSE, TRUE, or NA, (ignoring case)?"]==>id2(Logical)
    id1(Variable)==>B["2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)"]==>id3(Number)
    id1(Variable)==>C["3. Does it match the ISO8601 standard?"]==>id4(Date/Date-time)
    id1(Variable)==>D["4. None of the above"]==>id5(String)
    style id1 fill:#1e4655,color:#c7cdac,stroke:#c7cdac
    style id2 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id3 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id4 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id5 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style A fill:#FFFFFF,color:#000000,stroke:#000000
    style B fill:#FFFFFF,color:#000000,stroke:#000000
    style C fill:#ffa07a,color:#000000,stroke:#000000
    style D fill:#FFFFFF,color:#000000,stroke:#000000

```

## How does `readr` parse different data types?

For each column in a data frame, `readr` functions pull the first 1000 rows and checks:

```{mermaid}
%%| echo: false
%%| fig-width: 11
%%| fig-height: 5.5
%%| fig-align: center
flowchart LR
    id1(Variable)==>A["1. Does it contain only F, T, FALSE, TRUE, or NA, (ignoring case)?"]==>id2(Logical)
    id1(Variable)==>B["2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)"]==>id3(Number)
    id1(Variable)==>C["3. Does it match the ISO8601 standard?"]==>id4(Date/Date-time)
    id1(Variable)==>D["4. None of the above"]==>id5(String)
    style id1 fill:#1e4655,color:#c7cdac,stroke:#c7cdac
    style id2 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id3 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id4 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style id5 fill:#c7cdac,color:#1e4655,stroke:#1e4655
    style A fill:#FFFFFF,color:#000000,stroke:#000000
    style B fill:#FFFFFF,color:#000000,stroke:#000000
    style C fill:#FFFFFF,color:#000000,stroke:#000000
    style D fill:#ffa07a,color:#000000,stroke:#000000

```

## Most Common Issue with Reading in Data

The most common problem that occurs when reading in data is having mixed data. Most often, given the heuristic provided in the last slide, will parse a variable as a character string to preserve whatever it contains. 

. . . 

Let's actually look at how the billboard data was read in: 

```{r}
glimpse(billboard_2000_raw) 
```

## What Went Wrong? 

Since `readr` uses the values in the first 1000 rows to guess the type of the column (integer, logical, numeric, character), if the first 1000 rows don't have any data, they will be coded as logical variables. 

. . . 

There are not many songs in the data that charted for 60+ weeksâ€”and none in the first 1000 that charted for 66+ weeks!

. . . 

`NA` is logical?^[More on this in a couple of weeks.]

```{r}
class(NA) # <1>
```

1. `class` returns the data type of its first argument. 








## Writing Delimited Files

Getting data out of R into a delimited file is very similar to getting it into R:

```{r}
write_csv(billboard_2000_raw, path = "billboard_data.csv")
```

This saved the data we pulled off the web in a file called `billboard_data.csv` in my working directory.

# Reshaping Data {background-image="images/tidyr.png" background-size="contain" background-opacity="0.25" background-position="center" .section-title background-color="#99a486"}

## Initial Spot Checks


First things to check after loading new data:

::: {.incremental}
* Did all the rows/columns from the original file make it in?
    + Check using `dim()` or `str()`
* Are the column names in good shape?
    + Use `names()` to check; fix with `rename()`
* Are there "decorative" blank rows or columns to remove?
    + `filter()` or `select()` out those rows/columns
:::

## Tidy Data

**Tidy data** (aka "long data") are such that:

::: {.incremental}
1. The values for a single observation are in their own row.
2. The values for a single variable are in their own column.
3. There is only one value per cell.
:::

. . . 

Why do we want tidy data?

* **Easier to understand** many rows than many columns
* Required for **plotting** in `ggplot2`
* Required for many types of **statistical procedures** (e.g. hierarchical or mixed effects models)
* Fewer issues with **missing values and "imbalanced"** repeated measures data

## Slightly "Messy" Data

::::{.columns}
:::{.column width="60%"}

| **Program**     | **First Year** | **Second Year** |
|-----------------|-----------:|---------:|
| Evans School    |     10     |    6    |
| Arts & Sciences |      5     |    6    |
| Public Health   |      2     |    3    |
| Other           |      5     |    1    |

:::
:::{.column width="40%"}

* What is an **observation**?
    + A group of students from a program of a given year
    

* What are the **variables**?
    + Program, Year


* What are the **values**?
    + Program: Evans School, Arts & Sciences, Public Health, Other
    + Year: First, Second -- **in column headings. Bad!**
    + Count: **spread over two columns!**
:::
::::

## Tidy Version

::::{.columns}
:::{.column width="50%"}

| **Program**     | **Year** | **Count** |
|-----------------|-----------:|---------:|
| Evans School    |     First |    10   |
| Evans School    |     Second   |    6    |
| Arts & Sciences |     First |    5    |
| Arts & Sciences |     Second   |    6    |
| Public Health   |     First |    2    |
| Public Health   |     Second   |    3    |
| Other           |     First |    5    |
| Other           |     Second   |    1    |
:::
:::{.column width="50%"}
* Each variable is a column.

* Each observation is a row.

* Each cell has a single value.
:::
::::

## Billboard is Just Ugly-Messy

```{r}
#| echo: false
billboard_2000_raw %>% 
  head(10)
```

::: aside
Week columns continue up to `wk76`!
:::

## Billboard

::: {.incremental}
* What are the **observations** in the data?
    + Song on the Billboard chart each week
* What are the **variables** in the data?
    + Year, artist, track, song length, date entered Hot 100, week since first entered Hot 100 (**spread over many columns**), rank during week (**spread over many columns**)
* What are the **values** in the data?
    + e.g. 2000; 3 Doors Down; Kryptonite; 3 minutes 53 seconds; April 8, 2000; Week 3 (**stuck in column headings**); rank 68 (**spread over many columns**)
:::

## `tidyr`

The `tidyr` package provides functions to tidy up data. 

. . . 

Key functions:

* **`pivot_longer()`**: takes a set of columns and pivots them down ("longer") to make two new columns (which you can name yourself): 
    * A `name` column that stores the original column names
    * A `value` with the values in those original columns

. . . 

* **`pivot_wider()`**: inverts `pivot_longer()` by taking two columns and pivoting them up and across ("wider") into multiple columns

. . . 

We're going to focus only on `pivot_longer` here, but know that it can be reversed!

## `pivot_longer()`

This function usually takes three arguments:

1. **cols**: The columns we want to modify
1. **names_to**: New variable name to store original columns
1. **values_to**: New variable name to store original values

## Example of `pivot_longer()`

```{r}
#| code-line-numbers: "|3-5"
library(tidyr)
billboard_2000 <- billboard_2000_raw %>%
  pivot_longer(cols=wk1:wk76,
               names_to ="week",
               values_to = "rank")
billboard_2000 %>% 
  head(5)
```

Now we have a single week column!

## Lots of missing values?!

```{r}
summary(billboard_2000$rank)
```

We don't want to keep the `r sum(is.na(billboard_2000$rank))` rows with missing ranks.

## Pivoting Better: `values_drop_na`

Adding the argument `values_drop_na = TRUE` to `pivot_longer()` will remove rows with missing ranks.

```{r}
#| code-line-numbers: "|5"
billboard_2000 <- billboard_2000_raw %>%
  pivot_longer(cols = wk1:wk76, 
               names_to = "week", 
               values_to = "rank", 
               values_drop_na = TRUE)
summary(billboard_2000$rank)
```

. . . 

No more `NA` values!

```{r}
dim(billboard_2000)
```

And way fewer rows!

## `parse_number()`

The week column is of they type character, but it should be numeric.

```{r}
head(billboard_2000$week)
```

. . . 

`parse_number()` grabs just the numeric information from a character string:

```{r}
#| code-line-numbers: "|2"
billboard_2000 <- billboard_2000 %>%
    mutate(week = parse_number(week))
summary(billboard_2000$week)
```

More sophisticated tools for character strings will be covered later in this course!

## Summary

* Importing/Exporting Data: `readr`
* Reshaping data: `tidyr`
* Dates and times `lubridate`

*Let's take a 10 minute break, then reconvene for an activity!*

## Activity!

In groups of 2-3, you will use the [Billboard data](https://raw.githubusercontent.com/vsass/CSSS508/main/Lectures/Lecture5/data/billboard.csv) to investigate a question:

1. Write down a question of interest that could be studied with this data
     * *Which/how many artists had #1 hits?*
     * *How does rank for each song change over time?*
     * *Is there a relationship between highest rank and length of song?*
2. Make the Billboard data *tidy*, perhaps using the code from this lecture.

3. Perform additional steps (if necessary) to help answer your question:
    * Perhaps using `filter`, `select`, `group_by`, `mutate`, `summarize`, etc.

4. Make a plot or table that answers your question and write down your answer in a sentence.

5. Send me your question, plot/table, and written answer on Canvas

## Example: Question

**Question:** Do songs that hit #1 have a different trajectory than those that don't?

```{r}
billboard_2000_question <- billboard_2000 %>%
    group_by(artist, track) %>%
    mutate(`Weeks at #1` = sum(rank == 1),
           `Peak Rank`   = ifelse(any(rank == 1),
                                  "Hit #1",
                                  "Didn't hit #1")) 
```

::: aside
Note: `any(rank==1)` checks to see if *any* value of `rank` is equal to one for the given `artist` and `track`
:::

## Example Visualization

::: {.panel-tabset}

### Code

```{r}
library(ggplot2)
library(ggthemes)
billboard_trajectories <- 
  ggplot(data = billboard_2000_question,
         aes(x = week, y = rank, group = track,
             color = `Peak Rank`)) +
  geom_line(aes(size = `Peak Rank`), alpha = 0.4) +
  theme_tufte() +
  xlab("Week") + ylab("Rank") +
  scale_color_manual(values = c("black", "red")) +
  scale_size_manual(values = c(0.25, 1)) +
  theme(legend.position = c(0.90, 0.75),
        legend.background = element_rect(fill = "transparent"))
```

### Charts of 2000: Beauty!

```{r}
#| fig-height: 6
#| fig-width: 12
billboard_trajectories
```
:::

::: aside
Songs that reach #1 on the Billboard charts appear to last >20 weeks on the charts, while other songs very rarely make it past that point.
:::

# Homework

## Homework 4

*On [Course Website!*](https://vsass.github.io/CSSS508/Homework/HW5/homework4.html)

## Due dates

```{r}
#| echo: false
#| message: false
#| warning: false

# reading in base due date schedule
source("../due_dates_schedule.R")

make_due_date_table(4)
```