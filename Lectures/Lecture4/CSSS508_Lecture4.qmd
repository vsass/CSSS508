---
execute: 
  echo: true
  message: false
  warning: false
  fig-format: "svg"
format: 
  revealjs:
    highlight-style: a11y-dark
    reference-location: margin
    theme: lecture_styles.scss
    slide-number: true
    code-link: true
    chalkboard: true
    incremental: false 
    smaller: true
    preview-links: true
    code-line-numbers: true
    history: false
    progress: true
    link-external-icon: true
    code-annotations: hover
    pointer:
      color: "#b18eb1"
revealjs-plugins:
  - pointer
---

```{r}
#| echo: false
#| cache: false
require(downlit)
require(xml2)
require(tidyverse)
library(gapminder)
#options(width = 90)
```

## {#title-slide data-menu-title="Manipulating and Summarizing Data" background="#1e4655" background-image="../../images/csss-logo.png" background-position="center top 5%" background-size="50%"}

[Manipulating and Summarizing Data]{.custom-title}

[CS&SS 508 • Lecture 4]{.custom-subtitle}

[24 October 2023]{.custom-subtitle2}

[Victoria Sass]{.custom-subtitle3}

# Roadmap{.section-title background-color="#99a486"}

---

:::: {.columns}

::: {.column width="50%"}

<br>

### Last time, we learned:

* Best Practices
  * Code Style
  * Workflow
* Reproducible Research
* Indexing vectors & dataframes in Base `R`
:::

::: {.column width="50%"}

<br> 

::: {.fragment}
### Today, we will cover:

* Logical Operators
* Subsetting data
* Modifying data 
* Summarizing data
* Merging data
:::

:::

::::

## Death to Spreadsheets

Tools like *Excel* or *Google Sheets* let you manipulate spreadsheets using functions.

::: {.incremental}
* Spreadsheets are *not reproducible*: It's hard to know how someone changed the raw data!
* It's hard to catch mistakes when you use spreadsheets^[Don't be the next sad Research Assistant who makes headlines with an Excel error! ([Reinhart & Rogoff, 2010](http://www.bloomberg.com/news/articles/2013-04-18/faq-reinhart-rogoff-and-the-excel-error-that-changed-history))].
:::
 
. . .  
 
Today, we'll use `R` to manipulate data more *transparently* and *reproducibly*.

# Logical Operators{.section-title background-color="#99a486"}

## Data types in `R`

Going back to our list of data types in `R`: 

. . . 

* ~~Factors~~
* ~~Date/Date-time~~
* Logical
* Numeric
* Missing Values
* Strings

## Data types in `R`

Going back to our list of data types in `R`: 

* ~~Factors~~
* ~~Date/Date-time~~
* <span style="color:#e15759">Logical</span>
* Numeric
* Missing Values
* Strings

## Booleans

The simplest data type is a boolean, or binary, variable: `TRUE` or `FALSE`^[or `NA`]. 

. . . 

More often than not our data don't actually have a variable with this data type, but they are definitely created and evalutated in the data manipulation and summarizing process. 

. . . 

Logical operators refer to base functions which allow us to **test if a condition** is present between two objects. 

. . . 

For example, we may test

+ Is A equal to B?
+ Is A greater than B?
+ Is A within B?

. . . 

Naturally, these types of expressions produce a binary outcome of `T` or `F` which enables us to transform our data in a variety of ways!

## Logical Operators in `R`
  
#### Comparing objects
:::: {.columns}

::: {.column width="19%"}
::: {.fragment}
* `==`: 
* `!=`: 
* `>`, `>=`, `<`, `<=`: 
* `%in%`: 
:::
:::

::: {.column width="81%"}

::: {.fragment}
* is equal to^[Note: there are TWO equal signs here!]
* not equal to
* less than, less than or equal to, etc.
* used when checking if equal to one of several values
:::
:::

::::

:::{.fragment}
#### Combining comparisons
:::

:::: {.columns}

::: {.column width="19%"}
::: {.fragment}
* `&`: 
* `|`: 
* `!`: 
* `xor()`:
:::
:::

::: {.column width="81%"}

::: {.fragment .bullet-spacing}
* **both** conditions need to hold (AND)\
* **at least one** condition needs to hold (OR)\
* **inverts** a logical condition (`TRUE` becomes `FALSE`, vice versa)\
* **exclusive OR** (i.e. x or y but NOT both)
:::
:::

::::

::: aside
You may also see `&&` and `||` but they are what's known as short-circuiting operators and are not to be used in `dplyr` functions (used for programming not data manipulation); they'll only ever return a single `TRUE` or `FALSE`.
:::

## Unexpected Behavior

Be careful using `==` with numbers: 

. . . 

```{r}
x <- c(1 / 49 * 49, sqrt(2) ^ 2)
x
x == c(1, 2) # <1> 
print(x, digits = 16) # <2>
```

1. Computers store numbers with a fixed number of decimal places so there’s no way to *precisely* represent decimals. 
2. `dplyr::near()` is a useful alternative which ignores small differences. 

. . . 

Similarly mysterious, missing values (`NA`) represent the unknown. Almost anything conditional involving `NA`s will also be unknown:

```{r}
NA > 5
10 == NA
NA == NA # <3> 
```

3. The logic here: if you have one unknown and a second unknown, you don't actually know if they equal one another!

. . .  

This is the reason we use `is.na()` to check for missingness. 

```{r}
is.na(c(NA, 5))
```

## Examples of Logical Operators

Let's create two objects, `A` and `B`

```{r}
A <- c(5, 10, 15)
B <- c(5, 15, 25)
```

. . . 

Comparisons:

```{r}
A == B
A > B
A %in% B # <1>
```
1. Will return a vector the length of `A` that is `TRUE` whenever a value in `A` is anywhere in `B`. <br> **Note**: You CAN use `%in%` to search for `NA`s.

. . . 

Combinations: 

```{r}
A > 5 & A <= B 
B < 10 | B > 20 # <2>
!(A == 10)
```
2. Be sure not to cut corners (i.e. writing <br> `B < 10 | > 20`). The code won't technically error but it won't evaluate the way you expect it to. Read more about the confusing logic behind this [here](https://r4ds.hadley.nz/logicals#order-of-operations). 

## Logical Summaries

:::: {.columns}

::: {.column width="19%"}
::: {.fragment}
* `any()`: 
* `all()`: 
:::
:::

::: {.column width="81%"}

::: {.fragment}
* the equivalent of `|`; it’ll return `TRUE` if there are any `TRUE`’s in x
* the equivalent of `&`; it’ll return `TRUE` only if all values of x are `TRUE`’s
:::
:::

::::

. . .

```{r}
C <- c(5, 10, NA, 10, 20, NA)
any(C <= 10) # <1> 
all(C <= 20)
all(C <= 20, na.rm = TRUE) # <2>
mean(C, na.rm = TRUE) # <3> 

```

1. Like other summary functions, they'll return `NA` if there are any missing values present and it's `FALSE`. 
2. Use `na.rm = TRUE` to remove `NA`s prior to evaluation. 
3. When you evaluate a logical vector numerically, `TRUE` = 1 and `FALSE` = 0. This makes `sum()` and `mean()` useful when summarizing logical functions (sum gives number of `TRUE`s and mean gives the proportion). 

## Conditional transformations

<ins>**`if_else()`**</ins>

If you want to use one value when a condition is `TRUE` and another value when it’s `FALSE`.

. . . 

```{r}
#| eval: false
if_else(condition = "A logical vector", 
        true = "Output when condition is true", 
        false = "Output when condition is false")
```

. . . 

```{r}
x <- c(-3:3, NA)
if_else(x > 0, "+ve", "-ve", "???") # <1> 
```
1. There’s an optional fourth argument, `missing` which will be used if the input is `NA`.

. . . 

<ins>**`case_when()`**</ins>

A very useful extension of `if_else()` for multiple conditions^[Note that if multiple conditions match in `case_when()`, only the first will be used. 
]. 

. . . 

```{r}
case_when(
  x == 0   ~ "0",
  x < 0    ~ "-ve", 
  x > 0    ~ "+ve",
  is.na(x) ~ "???" # <2>
) # <3> 
```

2. Use `.default` if you want to create a “default”/catch all value. 
3. Both functions require compatible types: i.e. numerical and logical, strings and factors, dates and datetimes, `NA` and everything. 

# {data-menu-title="`dplyr`" background-image="images/dplyr.png" background-size="contain" background-position="center" .section-title background-color="#1e4655"}

## `dplyr`

Today, we'll use tools from the `dplyr` package to manipulate data! 

* Like `ggplot2`, `dplyr` is part of the *Tidyverse*, and included in the `tidyverse` package. 

```{r}
library(tidyverse)
```

. . . 

To demonstrate data transformations we're going to use the `nycflights13` dataset, which you'll need to download and load into `R`

```{r}
# Download and load data
# install.packages("nycflights13") # <1>
library(nycflights13) # <2>
```

1. Run in console. 
2. Load into `R` session. 

. . . 

`nycflights13` includes five dataframes^[Note these are separate data frames, each needing to be loaded separately:], some of which contain missing data (`NA`):

```{r}
#| eval: false
data(flights) # <1> 
data(airlines) # <2>
data(airports) # <3>
data(planes) # <4>
data(weather) # <5>
```

1. flights leaving JFK, LGA, or EWR in 2013
2. airline abbreviations
3. airport metadata
4. airplane metadata
5. hourly weather data for JFK, LGA, and EWR

## Building Block of `dplyr`: Pipes

`dplyr` allows us to "pipe" data between functions using the (`%>%`) operator. So instead of nesting functions like this:

```{r}
log(mean(gapminder$pop))
```

. . . 

We can **pipe** them like this:

```{r}
gapminder$pop %>% mean() %>% log()
```

. . . 

+ Pipes read "left to right." (intuitive)
+ Nested functions read "inside to out." (kinda weird; gets unwieldy the more nested your code becomes)

# Subsetting data{.section-title background-color="#99a486"}

+ `filter()`
+ `select()`
+ `distinct()`

## Subset Rows: `filter`

We often get *big* datasets, and we only want some of the entries. We can subset rows using `filter`.

. . . 

```{r}
gapminder |> 
  filter(country == "China") |>
  head(4) # display first four rows
China <- gapminder |> 
  filter(country == "China")
```

(Now, `China` is an object in our environment which contains rows corresponding to China.)

## Subset Columns: `select`

What if we want to keep each entry, but only use certain variables? Use `select`!

. . . 

```{r}
gapminder |> 
  select(country,continent,year,lifeExp) |> 
  head(4)
```

## Dropping columns with `select`

Alternatively, we can use `select()` to drop variables using a `-` sign: 

```{r}
gapminder |> 
  select(-continent, -pop, -lifeExp) |> 
  head(4)
```

## Finding Unique Rows: `distinct`

You may want to find the unique combinations of variables in a dataset.  Use `distinct`

. . . 

```{r}
gapminder |> 
  distinct(continent, year) |> 
  head(6)
```

## `distinct` drops variables!

By default, `distinct()` drops unused variables. If you don't want to drop them, add the argument `.keep_all = TRUE`:

```{r}
gapminder |> 
  distinct(continent, year, .keep_all=TRUE) |> 
  head(6)
```

# Modifying data{.section-title background-color="#99a486"}

+ `arrange()`
+ `rename()`
+ `mutate()`

## Sorting data by rows: `arrange`

Sometimes it's useful to sort rows in your data, in ascending (low to high) or descending (high to low) order. We do that with `arrange`.

. . . 

```{r}
US_and_Canada <- gapminder |> 
  filter(country %in% c("United States","Canada"))
US_and_Canada |> 
  arrange(year,lifeExp) |> 
  head(4)
```

## Sorting data by rows: `arrange`

To sort in descending order, using `desc()` within `arrange`

```{r}
US_and_Canada |> 
  arrange(desc(pop)) |> 
  head(4)
```

## Rename variables: `rename`

You may receive data with unintuitive variable names. You can change them using `rename()`.

. . . 

```{r}
US_and_Canada |> 
  rename(life_expectancy = lifeExp) |>
  head(4)
```

::: aside
\* NOTE 1: I did *not* re-save the object `US_and_Canada`, so the name change is *not* permanent!

\* NOTE 2: I recommend **against** using spaces in a name! It makes things *really hard* sometimes!!
:::

## Create new columns: `mutate`

You can add new columns to a data frame using `mutate()`. 

. . . 

For example, perhaps we wish to state the population in millions:

```{r}
#| code-line-numbers: "3"
US_and_Canada |> 
  select(country, year, pop) |>
  mutate(pop_millions = pop / 1000000) |> 
  head(5)
```

# Summarizing data{.section-title background-color="#99a486"}

+ `summarize()`
+ `group_by()`

## Summarizing data: `summarize`

**`summarize()`** calculates summaries of variables in your data:

* Count the number of rows
* Calculate the mean
* Calculate the sum
* Find the minimum or maximum value

You can use any function inside `summarize()` that aggregates *multiple values* into a *single value* (like `sd()`, `mean()`, or `max()`).

## `summarize()` Example

For the year 1982, let's summarize some values in `gapminder`

```{r}
gapminder |> 
  filter(year == 1982) |>
  summarize(number_observations = n(),
            max_lifeexp = max(lifeExp),
            mean_pop = mean(pop),
            sd_pop = sd(pop))
```

## Summarizing data by groups: `group_by`

What if we want to summarize data by category? Use `group_by` **and** `summarize`

. . . 

Functions after `group_by()` are computed *within each group* as defined by variables given, rather than over all rows at once.

## `group_by()` Example

```{r}
#| code-line-numbers: "1-2"
US_and_Canada |> group_by(year) |>  
  summarize(total_pop = sum(pop)) |> 
  head(4)
```

Because we did `group_by()` with `year` then used `summarize()`, we get *one row per value of `year`*!

# Merging Data {background-image="images/dplyr.png" background-size="contain" background-opacity="0.25" background-position="center" .section-title background-color="#99a486"}

## Joining Data

Oftentimes our data will be spread across multiple datasets. To properly analyze these data we'll need to join them together into one dataframe. 

. . . 

To do this we'll be using the various **join** functions from the `dplyr` package. 

. . . 



## Joining in Concept

We need to think about the following when we want to merge data frames A and B:

::: {.fragment}
* Which rows are we keeping from each data frame?
:::

::: {.fragment}
* Which columns are we keeping from each data frame?
:::

::: {.fragment .fade-in}
::: {.fragment .highlight-red}
* Which variables determine whether rows match?
:::
:::

## Keys

Keys are the way that two datasets are connected to one another. The two types of keys are: 

::: {.incremental}
1. **Primary**: a variable or set of variables that uniquely identifies each observation.
    i) When more than one variable makes up the primary key it's called a **compound key**
2. **Foreign**: a variable (or set of variables) that corresponds to a primary key in another table.
:::

## Primary Keys <span style="color:#99a486">{{< fa scroll >}}</span> {.scrollable} 

Let's look at our data to gain a better sense of what this all means. 

::: {.panel-tabset}

### `airlines` 

::: {.smaller-font}
`airlines` records two pieces of data about each airline: its carrier code and its full name. You can identify an airline with its two letter carrier code, making `carrier` the primary key.
:::

```{r}
airlines 
```

### `airports`

::: {.smaller-font}
`airports` records data about each airport. You can identify each airport by its three letter airport code, making `faa` the primary key.
:::

```{r}
airports
```


### `planes`

::: {.smaller-font}
`planes` records data about each plane. You can identify a plane by its tail number, making `tailnum` the primary key.
:::

```{r}
planes
```


### `weather`

::: {.smaller-font}
`weather` records data about the weather at the origin airports. You can identify each observation by the combination of location and time, making `origin` and `time_hour` the compound primary key.
:::

```{r}
weather
```

### `flights`

::: {.smaller-font}
`flights` actually contains **foreign keys** that correspond to the primary keys of the other datasets.
:::

```{r}
flights
```

:::


## Foreign Keys

![Note: grey shading indicates the primary key for that particular dataset.](images/relational.png){fig-align="center"}

::: {.incremental}
* `flights$origin` --> `airports$faa`
* `flights$dest` --> `airports$faa`
* `flights$origin`-`flights$time_hour` --> `weather$origin`-`weather$time_hour`.
* `flights$tailnum` --> `planes$tailnum`
* `flights$carrier` --> `airlines$carrier`
:::

## Checking Keys

A nice feature of these data are that the primary and foreign keys have the same name and almost every variable name used across multiple tables has the same meaning.^[With the exception of `year`: it means year of departure in `flights` and year of manufacture in `planes`. ] This isn't always the case!^[We'll cover how to handle this shortly.]

. . . 

It is good practice to make sure your primary keys actually uniquely identify an observation and that they don't have any missing values. 

. . . 

```{r}
#| output-location: fragment
planes |> 
  count(tailnum) |> # <1>
  filter(n > 1) # <1> 
```

1. If your primary keys uniquely identify each observation you'll get an empty tibble in return. 

. . . 

```{r}
planes |> 
  filter(is.na(tailnum)) # <2>
```

2. If none of your primary keys are missing you'll get an empty tibble in return here too. 

## Surrogate Keys

Sometimes you'll want to create an index of your observations to serve as a surrogate key because the compound primary key is not particlarly easy to reference. 

. . . 

For example, our `flights` dataset has three variables that uniquely identify each observation: `time_hour`, `carrier`, `flight`.

. . . 

```{r}
#| output-location: fragment
flights2 <- flights |> 
  mutate(id = row_number(), .before = 1) # <1> 
flights2
```

1. `row_number()` simply specifies the row number of the dataframe and `.before = 1` puts it as the first column. 

## Basic (Equi-) Joins

All join functions have the same basic interface: they take a **pair** of data frames and return **one** data frame. 

. . . 

The order of the rows and columns is primarily going to be determined by the first data frame. 

. . . 

`dplyr` has two types of joins: *mutating* and *filtering.* 

<br>

:::: {.columns}

::: {.column width="50%"}

::: {.fragment}
#### Mutating Joins 
Add new variables to one data frame from matching observations from another data frame. 

* `left_join()`
* `right_join()`
* `inner_join()`
* `full_join()`
:::

:::

::: {.column width="50%"}

::: {.fragment}
#### Filtering Joins 
Filter observations from one data frame based on whether or not they match an observation in another data frame. 

* `semi_join()`
* `anti-join()`
:::

:::

::::

## `Mutating Joins`

:::: {.columns}

::: {.column width="50%"}

<br>

::: {.fragment}
![](images/joins_setup.png)
:::
:::

::: {.column width="50%"}

<br>

::: {.fragment}
![](images/joins_setup2.png)
:::
:::

::::

## `left_join()` <span style="color:#99a486">{{< fa scroll >}}</span> {.scrollable} 

![](images/joins_left.png){fig-align="center"}

::: aside
::: {.incremental}
* The most common type of join
* Appends columns from `y` to `x` by the rows in `x`
    + `NA` added if there is nothing from `y`
* Natural join: when all variables that appear in both datasets are used as the join key
    + If the join_by() argument is not specified, `left_join()` will automatically join by all columns that have names and values in common. 
:::
:::

## `left_join` in `nycflights13`

```{r}
flights2 <- flights |> 
  select(year, time_hour, origin, dest, tailnum, carrier)
```

With only the pertinent variables from the `flights` dataset, we can see how a `left_join` works with the `airlines` dataset. 

```{r}
#| output-location: fragment
#| message: true
flights2 |>
  left_join(airlines)
```

## Different variable meanings

```{r}
#| output-location: fragment
#| message: true
flights2 |> 
  left_join(planes)
```

. . . 

When we try to do this, however, we get a bunch of `NA`s. Why? 

## Different variable meanings

```{r}
#| message: true
flights2 |> 
  left_join(planes)
```

*Join is trying to use tailnum and year as a compound key.* While both datasets have `year` as a variable, they mean different things. Therefore, we need to be explicit here about what to join by. 

## Different variable meanings

```{r}
#| output-location: fragment
flights2 |> 
  left_join(planes, join_by(tailnum)) # <1>
```

1. `join_by(tailnum)` is short for `join_by(tailnum == tailnum)` making these types of basic joins equi joins. 

::: aside
When you have the same variable name but they mean different things you can specify a particular suffix with the `suffix` argument.
:::

## Different variable names

If you have keys that have the same meaning (values) but are named different things in their respective datasets you'd also specify that with `join_by()`

. . . 

```{r}
#| output-location: fragment
flights2 |> 
  left_join(airports, join_by(dest == faa)) # <1>
```

1. This used to be `by = c("dest" = "faa")` which you still might see in older code. 

. . . 

This will match `dest` to `faa` for the join and then drop `faa`. 

## Different variable names

You can request dplyr to keep both keys with `keep = TRUE` argument. 

. . . 

```{r}
#| output-location: fragment
flights2 |> 
  left_join(airports, join_by(dest == faa), keep = TRUE) 
```

## `right_join()`

![Has the same interface as a left_join but keeps all rows in `y` instead of `x`](images/joins_right.png){fig-align="center"}

## `inner_join()`

![Has the same interface as a left_join but only keeps rows that occur in both x and y](images/joins_inner.png){fig-align="center"}

## `full_join()`

![Has the same interface as a left_join but keeps all rows in either x or y](images/joins_full.png){fig-align="center"}

## `Filtering Joins`

:::: {.columns}

::: {.column width="50%"}

<br>

::: {.fragment}
![](images/joins_setup.png)
:::
:::

::: {.column width="50%"}

<br>

::: {.fragment}
![](images/joins_setup2.png)
:::
:::

::::

## `semi_join()`

![Keeps all rows in x that have a match in y](images/joins_semi.png){fig-align="center"}


## `semi_join()` in `nycflights13`

We could use a semi-join to filter the airports dataset to show just the origin airports.

. . . 

```{r}
#| output-location: fragment
airports |> 
  semi_join(flights2, join_by(faa == origin))
```


## `anti_join()`

![Returns all rows in x that don’t have a match in y](images/joins_anti.png){fig-align="center"}

## `anti_join()` in `nycflights13`

We can find rows that are missing from airports by looking for flights that don’t have a matching destination airport.

. . . 

```{r}
#| output-location: fragment
airports |> 
  semi_join(flights2, join_by(faa == origin))
```

::: aside
This type of join is useful for finding missing values that are implicit in the data (i.e. `NA`s that don't show up in the data but only exist as an absence.)
:::

## More Than One Match

![](images/joins_match-types.png){fig-align="center"}

. . . 

There are three possible outcomes for a row in x:

::: {.incremental}
* If it doesn’t match anything, it’s dropped.
* If it matches 1 row in y, it’s preserved.
* If it matches more than 1 row in y, it’s duplicated once for each match.
:::

. . . 

What happens if we match on more than one row? 

## More Than One Match

```{r}
#| output-location: fragment
#| message: true
df1 <- tibble(key = c(1, 2, 2), val_x = c("x1", "x2", "x3"))
df2 <- tibble(key = c(1, 2, 2), val_y = c("y1", "y2", "y3"))

df1 |> 
  inner_join(df2, join_by(key))
```


. . . 

If you are doing this deliberately, you can set relationship = "many-to-many", as the warning suggests.

::: aside
Given their nature, filtering joins never duplicate rows like mutating joins do. They will only ever return a subset of the datasets.
:::

## Non-Equi Joins

The joins we've discussed thus far have all been equi-joins, where the rows match if the x key equals the y key. But you can also specify other types of relationships. 

. . . 

`dplyr` has four different types of non-equi joins: 

. . . 

:::: {.columns}

::: {.column width="50%"}

* **Cross joins** match every pair of rows.
:::

::: {.column width="50%"}

![](images/joins_cross.png){width=25% .absolute top=150 right=150}

:::
::::

::: aside
Cross joins, aka self-joins, are useful when generating permutations (e.g. creating every possible combination of values). This comes in handy when creating datasets of predicted probabilities for plotting in ggplot. 
:::

## Non-Equi Joins

The joins we've discussed thus far have all been equi-joins, where the rows match if the x key equals the y key. But you can also specify other types of relationships. 

`dplyr` has four different types of non-equi joins: 

:::: {.columns}

::: {.column width="50%"}

* **Cross joins** match every pair of rows.
* **Inequality joins** use <, <=, >, and >= instead of ==.
    * **Overlap joins** are a special type of inequality join designed to work with ranges^[Overlap joins provide three helpers that use inequality joins to make it easier to work with intervals: `between()`, `within()`, `overlaps()`. Read more about their functionality and specifications [here](https://dplyr.tidyverse.org/reference/join_by.html?q=within#overlap-joins).].

:::

::: {.column width="50%"}
![](images/joins_inequality.png){width=30% .absolute top=158 right=120}
:::
::::

::: aside
Inequality joins can be used to restrict the cross join so that instead of generating all permutations, we generate all combinations.
:::

## Non-Equi Joins

The joins we've discussed thus far have all been equi-joins, where the rows match if the x key equals the y key. But you can also specify other types of relationships. 

`dplyr` has four different types of non-equi joins: 

:::: {.columns}

::: {.column width="50%"}

* **Cross joins** match every pair of rows.
* **Inequality joins** use <, <=, >, and >= instead of ==.
    * **Overlap joins** are a special type of inequality join designed to work with ranges.
* **Rolling joins** are similar to inequality joins but only find the closest match.

:::

::: {.column width="50%"}
![](images/joins_rolling.png){width=42% .absolute top=155 right=35}
:::
::::

::: aside
Rolling joins are a special type of inequality join where instead of getting every row that satisfies the inequality, you get just the closest row. You can turn any inequality join into a rolling join by adding closest().
:::

# Lab{.section-title background-color="#99a486"}

1. Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns?

```{r}
worst_delays <- flights |> 
  select(dep_delay, origin, time_hour) |> 
  left_join(weather, join_by(origin, time_hour))
```























## Why merge?!

In practice, we often collect data from different sources. To analyze the data, we usually must first combine (merge) them.

. . . 

For example, imagine you would like to study county-level patterns with respect to age and grocery spending. However, you can only find,

* County level age data from the US Census, and 
* County level grocery spending data from the US Department of Agriculture

. . . 

Merge the data!!

## Merging in Concept

When merging datasets `A` and `B`, ask yourself the following two questions:
  
. . . 

* Which **rows** do I want to keep?

  + All rows in `A`?
  + All rows in both `A` and `B`?
  
. . . 

* How do my datasets **connect**?

  + Is there a specific variable they have in common?
  + Multiple variables they have in common?
  
## Which Rows to Keep:


We'll focus on two types of joins^[Other types include `right_join`, `inner_join`, `semi_join`, and `anti_join`, but we won't study those here.]:

* `A |> left_join(B)`: keeps `A` and adds variables from `B` after matching.

* `A |> full_join(B)`: keeps all of `A` and `B`, but combines rows when possible.

## Matching Criteria

We have to tell R **which variables** to use when merging datasets! Rows are matched when the values in matching variables are equivalent.

. . . 

* `by = c("County")`: Both datasets have a `County` variable, match on this!

. . . 

* `by = c("CountyName" = "County_Name")`: Match `CountyName` in `A` with `County_Name` in `B`

## Example: `nycflights13` Data

The `nycflights13` package includes five data frames, some of which contain missing data (`NA`):

* `flights`: flights leaving JFK, LGA, or EWR in 2013
* `airlines`: airline abbreviations
* `airports`: airport metadata
* `planes`: airplane metadata
* `weather`: hourly weather data for JFK, LGA, and EWR

```{r}
# install.packages("nycflights13") # remember to do this in the console, not in your .R or .qmd document
library(nycflights13)
```

## Join Example 1

`flights` has one row per flight, with abbreviated airline names.

```{r}
flights |> 
  select(flight,origin,dest,carrier) |> 
  head(2)
```

. . . 

`airlines` has one row per airline, with airline abbreviations *and* full names

```{r}
airlines |> 
  head(2)
```

## Join Example 1 (continued)

Let's left join `flights` with `airlines` to add full airline name to each flight record!

```{r}
#| code-line-numbers: "3"
flights |> 
  select(flight,origin,dest,carrier) |>
  left_join(airlines, by = "carrier")  |> 
  head(5)
```
 
We now have one row per flight, with both carrier abbreviations and full names!

## Join Example #2

`flights` also includes a `tailnum` variable for each plane's tail number.

```{r}
flights |> 
  select(flight,origin,dest,tailnum) |> 
  head(2)
```

. . . 

`planes` includes a row for each plane type, including the manufacturer.

```{r}
planes |> 
  select(tailnum,year,manufacturer,model) |> 
  head(2)
```

## Join Example 2 (continued)

Let's left join `flights` with `planes` to add manufacture to each flight record!

```{r}
#| code-line-numbers: "3"
flights |> 
  select(flight,origin,dest,tailnum) |>
  left_join(planes, by = "tailnum")  |> 
  head(5)
```

A bunch of columns from `planes` are now in the dataset!

## Join Example 2 (continued)

Let's remove some of the "spare" columns

```{r}
#| code-line-numbers: "4"
flights |> 
  select(flight, origin, dest, tailnum) |>
  left_join(planes, by = "tailnum")  |> 
  select(flight, origin, dest, manufacturer, model) |>
  head(5)
```

# Summary{.section-title background-color="#99a486"}

* Logical Operators (`&, |, ==, <, %in%,` etc.)
* Subsetting (`filter, select, distinct`)
* Modifying (`arrange, rename, mutate`)
* Summarizing (`summarize, group_by`)
* Merging (`left_join, full_join`)

Let's take a 10-minute break, then come back together to practice!

## Activity

1. Create a new object that contains `gapminder` (1) observations from China, India, and United States after 1980, and (2) variables corresponding to country, year, population, and life expectancy. 
1. How many rows and columns does the object contain?
1. Save over your object after sorting the rows by year (ascending order) and population (descending order). Print the first 6 rows.
1. Add a new variable that contains population in billions.
1. By year, calculate the total population (in billions) across these three countries
1. In ggplot, create a line plot showing life expectancy over time by country. Make the plot visually appealing!

## Answers

Question 1:

```{r}
subset_gapminder <- gapminder |> 
  filter(country %in% c("China","India","United States"),  year > 1980 ) |>
  select(country, year, pop, lifeExp)
subset_gapminder |> head(n = 5)
```

## Answers

Question 2: 
```{r}
# Option 1
c(nrow(subset_gapminder), ncol(subset_gapminder))
# Option 2
glimpse(subset_gapminder)
# Option 3
dim(subset_gapminder)
```

. . . 

## Answers

Question 3:
```{r}
subset_gapminder <- subset_gapminder |> 
  arrange(year, desc(pop))

subset_gapminder |> head(6)
```

## Answers

Question 4:
```{r}
subset_gapminder <- subset_gapminder |> 
  mutate(pop_billions = pop/1000000000)

subset_gapminder |> head(n = 5)
```

## Answers

Question 5:

::: {.panel-tabset}

### Classic syntax

```{r}
subset_gapminder |> 
  group_by(year) |> 
  summarize(TotalPop_Billions = sum(pop_billions))
```

### New syntax (dplyr 1.1.0)

```{r}
subset_gapminder |> 
  summarize(TotalPop_Billions = sum(pop_billions), 
            .by = year)
```

This new syntax allows for per-operation grouping which means it is only active within a single verb at a time (as opposed to being applied to the entire tibble until `ungroup()` is called). You can more about this new feature [here](https://www.tidyverse.org/blog/2023/02/dplyr-1-1-0-per-operation-grouping/))

:::

## Answers

Question 6:

::: {.panel-tabset}

### Code

```{r}
#| eval: false
#| code-line-numbers: "|2,3,5|"
library(ggplot2) 
# install.packages("ggthemes") # run in console
library(ggthemes)
ggplot(subset_gapminder, aes(year, lifeExp, color = country, group = country)) +
  theme_tufte(base_size = 20) + 
  geom_point() + 
  geom_line() +
  xlab("Year") + 
  ylab("Life Expectancy (years)") +
  ggtitle("Life Expectancy (1982-2007)","China, India, and United States") +
  scale_x_continuous(breaks = c(1982, 1987, 1992, 1997, 2002, 2007), minor_breaks = c()) +
  ylim(c(50, 80)) + 
  scale_color_discrete(name = "Country") + 
  theme(legend.position = "bottom")
```

### Plot

```{r}
#| fig-height: 6
#| fig-width: 12
#| fig-align: center
#| echo: false
library(ggplot2)
# install.packages("ggthemes") # run in console
library(ggthemes)
ggplot(subset_gapminder, aes(year, lifeExp, color = country, group = country)) +
  theme_tufte(base_size = 20) + geom_point() + geom_line() +
  xlab("Year") + ylab("Life Expectancy (years)") +
  ggtitle("Life Expectancy (1982-2007)","China, India, and United States") +
  scale_x_continuous(breaks = c(1982, 1987, 1992, 1997, 2002, 2007), minor_breaks = c()) +
  ylim(c(50, 80)) + scale_color_discrete(name = "Country") + theme(legend.position = "bottom")
```

:::

# Homework{.section-title background-color="#99a486"}

## Homework 5 {.scrollable}

Create a qmd file (from scratch this time!) in which you answer each of the following questions. Be sure to display **all your code in the knitted** version (use throughout `echo: false`). 

Remember, the package `nycflights13` contains data on flights originating in NYC during the year 2013. There are three airports servicing NYC: JFK, LGA ("LaGuardia"), and EWR ("Newark").

1. Choose an airport outside New York, and count how many flights went to that airport from NYC in 2013. How many of those flights started at JFK, LGA, and EWR? (Hint: Use `filter`, `group_by`, and `summarize`)
2. The variable `arr_delay` contains arrival delays in minutes (negative values represent early arrivals). Make a `ggplot` histogram displaying arrival delays for 2013 flights from NYC to the airport you chose.
3. Use `left_join` to add weather data at departure to the subsetted data^[Hint 1: Match on `origin`, `year`, `month`, `day`, **and** `hour`!!]. Calculate the mean temperature by month at departure (`temp`) across all flights^[Hint 2: Use `mean(temp, na.rm=T)` to have R calculate an average after ignoring missing data values].
4. Investigate if there is a relationship between departure delay (`dep_delay`) and wind speed (`wind_speed`). Is the relationship different between JFK, LGA, and EWR? I suggest answering this question by making a plot and writing down a one-sentence interpretation.

As always, submit both the .qmd and knitted .html to Canvas.

<br>
<br>

## Due dates

```{r}
#| echo: false
#| message: false
#| warning: false

# reading in base due date schedule
source("../due_dates_schedule.R")

make_due_date_table(5)
```


